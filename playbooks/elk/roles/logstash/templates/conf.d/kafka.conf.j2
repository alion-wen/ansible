input {
	kafka {
		topics => "beats"
		auto_commit_interval_ms => "1000"
		bootstrap_servers => "{{ kafka_host }}:{{ kafka_port }}"
		client_id => "logstash"
		group_id  => "logstash"
		codec => "plain"
		consumer_threads => 2
	}
}

filter {

	mutate {
		gsub => [ "message", "[\\]", "" ]
    }

	grok {
		patterns_dir => ["patterns"]
		match => { "message" => "%{IP:remote_addr} - %{HTTPDUSER:remote_user} \[%{HTTPDATE:time_local}\] \"%{WORD:method} %{URIPATHPARAM:request} %{DATA:protocol_version}\" %{INT:status} %{INT:body_bytes_sent} %{QS:http_referer} %{QS:http_user_agent} \"%{DATA:http_x_forwarded_for}\" %{QS:host} \"%{NUMBER:request_time}\" \"%{INT:request_length}\" %{QS:upstream_addr} \"%{NUMBER:upstream_response_time}\" \"%{INT:upstream_status}\"" }
		match => { "client_ip" => "%{IP:http_x_forwarded_for}"}
		overwrite => [ "host" ]
		remove_field => [ "message" , "source" , "offset" ]
	}
	
	if [http_x_forwarded_for] !~ "-" {
		mutate {
			split => { "http_x_forwarded_for" => "," }
			add_field => { "client_ip" => "%{[http_x_forwarded_for][0]}"}
		}
	}

	date {
		match => [ "time_local" , "dd/MMM/yyyy:HH:mm:ss Z" ]
	}

	geoip {
		source => "client_ip"
	}

	useragent {
		source => "http_user_agent"
		target => "user_agent"
	}
}

output {
	elasticsearch {
    	hosts => ["{{ es_host }}:{{ es_port }}"]
        index => "logstash-%{type}-%{+YYYY.MM.dd}"
        flush_size => 20000
        idle_flush_time => 10
    }
	#stdout { codec => rubydebug }
}
